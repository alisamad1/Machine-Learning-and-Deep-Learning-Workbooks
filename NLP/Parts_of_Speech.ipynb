{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac3483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Paragraph = ''' \"Learning\" new skills like \"python\" and \"data\" analysis opens doors to the \"future\" of technology. With a strong foundation in \"computer\" science, one can build powerful \"algorithm\" solutions for real-world problems. The rise of \"cloud\" computing and \"network\" systems has made access to tools easier than ever. Whether you're analyzing trends or building models, understanding the core ideas helps drive innovation. Stay curious, keep practicing, and let your journey in tech begin with small, consistent steps toward growth and discovery.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3eaa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences= nltk.sent_tokenize(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a17a6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \"Learning\" new skills like \"python\" and \"data\" analysis opens doors to the \"future\" of technology.',\n",
       " 'With a strong foundation in \"computer\" science, one can build powerful \"algorithm\" solutions for real-world problems.',\n",
       " 'The rise of \"cloud\" computing and \"network\" systems has made access to tools easier than ever.',\n",
       " \"Whether you're analyzing trends or building models, understanding the core ideas helps drive innovation.\",\n",
       " 'Stay curious, keep practicing, and let your journey in tech begin with small, consistent steps toward growth and discovery.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba4a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4790cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f37e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('Learning', 'VBG'), (\"''\", \"''\"), ('new', 'JJ'), ('skills', 'NNS'), ('like', 'IN'), ('``', '``'), ('python', 'NN'), (\"''\", \"''\"), ('``', '``'), ('data', 'NNS'), (\"''\", \"''\"), ('analysis', 'NN'), ('opens', 'VBZ'), ('doors', 'NNS'), ('``', '``'), ('future', 'JJ'), (\"''\", \"''\"), ('technology', 'NN'), ('.', '.')]\n",
      "[('With', 'IN'), ('strong', 'JJ'), ('foundation', 'NN'), ('``', '``'), ('computer', 'NN'), (\"''\", \"''\"), ('science', 'NN'), (',', ','), ('one', 'CD'), ('build', 'NN'), ('powerful', 'JJ'), ('``', '``'), ('algorithm', 'NN'), (\"''\", \"''\"), ('solutions', 'NNS'), ('real-world', 'VBP'), ('problems', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('rise', 'NN'), ('``', '``'), ('cloud', 'NN'), (\"''\", \"''\"), ('computing', 'VBG'), ('``', '``'), ('network', 'NN'), (\"''\", \"''\"), ('systems', 'NNS'), ('made', 'VBD'), ('access', 'NN'), ('tools', 'NNS'), ('easier', 'JJR'), ('ever', 'RB'), ('.', '.')]\n",
      "[('Whether', 'NNP'), (\"'re\", 'VBP'), ('analyzing', 'VBG'), ('trends', 'NNS'), ('building', 'NN'), ('models', 'NNS'), (',', ','), ('understanding', 'VBG'), ('core', 'NN'), ('ideas', 'NNS'), ('helps', 'VBP'), ('drive', 'JJ'), ('innovation', 'NN'), ('.', '.')]\n",
      "[('Stay', 'NNP'), ('curious', 'JJ'), (',', ','), ('keep', 'VB'), ('practicing', 'NN'), (',', ','), ('let', 'VB'), ('journey', 'NN'), ('tech', 'VB'), ('begin', 'VB'), ('small', 'JJ'), (',', ','), ('consistent', 'JJ'), ('steps', 'NNS'), ('toward', 'IN'), ('growth', 'NN'), ('discovery', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## we wil;l find out the pos tag\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "   ## sentences[i] = \" \".join(words)\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ec57cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokens: expected a list of strings, got a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nltk\u001b[38;5;241m.\u001b[39mpos_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaj mahal is in Agra\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\KIIT\\Anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py:169\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mtag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\KIIT\\Anaconda3\\Lib\\site-packages\\nltk\\tag\\__init__.py:123\u001b[0m, in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Throws Error if tokens is of string type\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokens, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens: expected a list of strings, got a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m tagger\u001b[38;5;241m.\u001b[39mtag(tokens)\n",
      "\u001b[1;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag_sents(\"Taj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb67eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
